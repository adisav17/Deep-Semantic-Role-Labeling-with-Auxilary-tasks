{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adisav17/Deep-Semantic-Role-Labeling-with-Auxilary-tasks/blob/main/srl_bert_pred_pos_hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3kIsrUJ3Hok",
        "outputId": "5e2754f1-7817-4795-a055-04b9e740cb58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw2r-54k4KX5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics import precision_recall_curve, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi5IH4vI4NAj"
      },
      "outputs": [],
      "source": [
        "class SRLDataset(Dataset):\n",
        "    def __init__(self, sentences, predicates, labels, tokenizer, max_length):\n",
        "        self.sentences = sentences\n",
        "        self.predicates = predicates\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence = self.sentences[index]\n",
        "        predicate = self.predicates[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Tokenize sentence without special tokens to handle alignment\n",
        "        tokenized_sentence = self.tokenizer.tokenize(sentence)\n",
        "\n",
        "        # Initialize a list of labels with -100 (ignored by loss function) and the same length as the tokenized sentence\n",
        "        aligned_labels = [-100] * len(tokenized_sentence)\n",
        "\n",
        "        # Iterate through the original sentence words, labels, and their indices\n",
        "        words = sentence.split()\n",
        "        for word, lbl, idx in zip(words, label, range(len(words))):\n",
        "            # Tokenize the current word\n",
        "            subwords = self.tokenizer.tokenize(word)\n",
        "\n",
        "            # Assign the label to the first subword of the current word\n",
        "            subword_idx = tokenized_sentence.index(subwords[0], idx)\n",
        "            aligned_labels[subword_idx] = lbl\n",
        "\n",
        "        # Tokenize sentence and add [CLS] and [SEP] tokens\n",
        "        tokenized_sentence = self.tokenizer.encode(sentence, add_special_tokens=True, max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        input_ids = torch.tensor(tokenized_sentence, dtype=torch.long)\n",
        "\n",
        "        # Add [CLS] and [SEP] tokens to the aligned_labels and pad or truncate to match max_length\n",
        "        aligned_labels = [-100] + aligned_labels[:self.max_length - 2] + [-100]\n",
        "        aligned_labels = aligned_labels + [-100] * (self.max_length - len(aligned_labels))\n",
        "\n",
        "        # Convert the aligned_labels list to a torch tensor\n",
        "        aligned_labels = torch.tensor(aligned_labels, dtype=torch.long)\n",
        "\n",
        "        # Find index of predicate in tokenized sentence\n",
        "        predicate_idx = tokenized_sentence.index(self.tokenizer.encode(predicate)[1])\n",
        "\n",
        "        return input_ids, predicate_idx, aligned_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og1DEiTH4TKW"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCole66i4T1m"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNok_zcI4W4b"
      },
      "outputs": [],
      "source": [
        "def convert_file(file_path):\n",
        "    with open(file_path) as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    lines = [line.split() for line in lines]\n",
        "    sentences = []\n",
        "    tags = []\n",
        "    predicates = []\n",
        "    sentence = []\n",
        "    tag = []\n",
        "    curr_pred = None\n",
        "    exists_pred_in_sent = False\n",
        "    exists_arg_in_sent = False\n",
        "\n",
        "    for line in lines:\n",
        "        if len(line) != 0:\n",
        "            sentence.append(line[0])\n",
        "\n",
        "            if len(line) >= 6:\n",
        "                if line[5] == \"PRED\":\n",
        "                    curr_pred = line[0]\n",
        "                    exists_pred_in_sent = True\n",
        "\n",
        "                if line[5] == \"ARG1\":\n",
        "                    exists_arg_in_sent = True\n",
        "                    tag.append(1)\n",
        "                else:\n",
        "                    tag.append(0)\n",
        "            else:\n",
        "                tag.append(0)\n",
        "        else:\n",
        "            if exists_arg_in_sent and exists_pred_in_sent:\n",
        "                sentences.append(\" \".join(sentence))\n",
        "                tags.append(tag)\n",
        "                predicates.append(curr_pred)\n",
        "\n",
        "                exists_pred_in_sent = False\n",
        "                exists_arg_in_sent = False\n",
        "\n",
        "            sentence = []\n",
        "            tag = []\n",
        "            curr_pred = None\n",
        "\n",
        "    if len(sentence) > 0 and exists_arg_in_sent and exists_pred_in_sent:\n",
        "        sentences.append(\" \".join(sentence))\n",
        "        tags.append(tag)\n",
        "        predicates.append(curr_pred)\n",
        "\n",
        "    return sentences, tags, predicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WWf2r8r62vF",
        "outputId": "d16186f9-9eb7-467c-9317-3fa390e646e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSfDn7iY68Rp",
        "outputId": "d31b36ab-ff79-453f-cc1f-d2e0ecf3b4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/nlp_srl\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/nlp_srl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb3qlTgv4zWY"
      },
      "outputs": [],
      "source": [
        "sentences_1, labels_1, predicates_1 = convert_file('partitive_group_nombank.clean.train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MpMWYlV7AZ5"
      },
      "outputs": [],
      "source": [
        "sentences_2, labels_2, predicates_2 = convert_file('partitive_group_nombank.clean.test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "becFuEmJ7FOZ"
      },
      "outputs": [],
      "source": [
        "sentences_3, labels_3, predicates_3 = convert_file('partitive_group_nombank.clean.dev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSmlbng37Jx0",
        "outputId": "1fa04ae1-2366-4109-dacc-33d85ce57bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9584\n",
            "9584\n",
            "9584\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences_1))\n",
        "print(len(labels_1))\n",
        "print(len(predicates_1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4NYFy7c7VEp",
        "outputId": "1e957e0a-f843-4667-b0a8-1bccc11772e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "584\n",
            "584\n",
            "584\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences_2))\n",
        "print(len(labels_2))\n",
        "print(len(predicates_2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgTmo4587ac-",
        "outputId": "a3e7d4e6-fa5a-4016-fa80-820b3b6c85d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353\n",
            "353\n",
            "353\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences_3))\n",
        "print(len(labels_3))\n",
        "print(len(predicates_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sWzC_rWV7g4Y",
        "outputId": "0e15e1d8-1e7e-43aa-d144-59e117a22507"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The consensus view expects a 0.4 % increase in the September CPI after a flat reading in August .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sentences_3[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koGRukjL7p1O",
        "outputId": "2795bb88-f4c9-4425-9971-4e75dbbfa48b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "labels_3[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8DT1U2u7ymG",
        "outputId": "6044e44d-01f6-4b21-852d-784d9127bfba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['%', '%', '%', '%', '%']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "predicates_1[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7mNbMk977S2"
      },
      "outputs": [],
      "source": [
        "sentences_all = sentences_1.copy()\n",
        "labels_all = labels_1.copy()\n",
        "predicates_all = predicates_1.copy()\n",
        "\n",
        "sentences_all.extend(sentences_2)\n",
        "labels_all.extend(labels_2)\n",
        "predicates_all.extend(predicates_2)\n",
        "\n",
        "sentences_all.extend(sentences_3)\n",
        "labels_all.extend(labels_3)\n",
        "predicates_all.extend(predicates_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz7NKCha9JIR",
        "outputId": "8c2164de-7ec5-454c-9a05-9afb83fdedb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10521\n",
            "10521\n",
            "10521\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences_all))\n",
        "print(len(labels_all))\n",
        "print(len(predicates_all))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NribvqAL9RJ2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Combine sentences, labels, and predicates into a list of tuples\n",
        "combined_data = list(zip(sentences_all, labels_all, predicates_all))\n",
        "\n",
        "# Shuffle the combined data using a random seed for reproducibility\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "random.shuffle(combined_data)\n",
        "\n",
        "# Split the shuffled data into training and validation sets\n",
        "split_ratio = 0.8  \n",
        "split_index = int(len(combined_data) * split_ratio)\n",
        "\n",
        "train_data = combined_data[:split_index]\n",
        "val_data = combined_data[split_index:]\n",
        "\n",
        "# Separate sentences, labels, and predicates for the train and validation sets\n",
        "train_sentences, train_labels, train_predicates = zip(*train_data)\n",
        "val_sentences, val_labels, val_predicates = zip(*val_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJhpwldO-IN6",
        "outputId": "25547c89-8ed5-478e-c890-73cf1a9cb308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8416\n",
            "8416\n",
            "8416\n"
          ]
        }
      ],
      "source": [
        "print(len(train_sentences))\n",
        "print(len(train_labels))\n",
        "print(len(train_predicates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8guN900B-TKK",
        "outputId": "ae726172-cce4-45a6-fd7d-d18de1981af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2105\n",
            "2105\n",
            "2105\n"
          ]
        }
      ],
      "source": [
        "print(len(val_sentences))\n",
        "print(len(val_labels))\n",
        "print(len(val_predicates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqEs-WIu-_7k"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "count = 0\n",
        "max_length = 0\n",
        "for i in range(len(train_sentences)):\n",
        "\n",
        "  if(len(train_labels[i])>max_length):\n",
        "    max_length = len(train_labels[i])\n",
        "\n",
        "  count+=1\n",
        "  X.append(len(train_sentences[i].split()) == len(train_labels[i]))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t86mRrqtEluK",
        "outputId": "d6e2e68a-18c4-4079-9369-b0d928f58013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108\n",
            "8416\n",
            "8416\n"
          ]
        }
      ],
      "source": [
        "print(max_length)\n",
        "print(sum(X))\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3rW6t3pEqAw"
      },
      "outputs": [],
      "source": [
        "class SRLModel(nn.Module):\n",
        "    def __init__(self, bert_model, hidden_size, num_labels, lstm_hidden_size=128, dropout_rate=0.1):\n",
        "        super(SRLModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.lstm = nn.LSTM(input_size=hidden_size*2, hidden_size=lstm_hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(lstm_hidden_size, num_labels)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, predicate_idx, padded_labels):\n",
        "        attention_mask = input_ids.ne(0)\n",
        "\n",
        "        # obtain BERT embeddings\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
        "\n",
        "        # obtain predicate embeddings\n",
        "        batch_size, seq_len, hidden_size = bert_output.shape\n",
        "        predicate_idx_expanded = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1).to(input_ids.device)\n",
        "        predicate_embedding = torch.gather(bert_output, 1, predicate_idx_expanded.unsqueeze(-1).expand(-1, -1, hidden_size))\n",
        "        predicate_embedding = predicate_embedding.squeeze(1)\n",
        "\n",
        "        # obtain positional embeddings\n",
        "        position_ids = torch.arange(input_ids.shape[1], dtype=torch.long, device=input_ids.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand(input_ids.shape)\n",
        "        position_embeddings = self.bert.embeddings.position_embeddings(position_ids)\n",
        "\n",
        "        # add positional embeddings to BERT embeddings\n",
        "        embeddings = bert_output + position_embeddings\n",
        "\n",
        "        # concatenate word and predicate embeddings\n",
        "        embeddings = torch.cat([embeddings, predicate_embedding], dim=-1)\n",
        "\n",
        "        # pass embeddings through LSTM layer\n",
        "        lstm_output, _ = self.lstm(embeddings)\n",
        "\n",
        "        # apply dropout\n",
        "        lstm_output = self.dropout(lstm_output)\n",
        "\n",
        "        # pass LSTM output through feedforward layer to obtain predictions\n",
        "        logits = self.fc(lstm_output)\n",
        "\n",
        "        # mask padding positions\n",
        "        mask = padded_labels.ne(-100)\n",
        "\n",
        "        masked_logits = logits[mask]\n",
        "        masked_labels = padded_labels[mask]\n",
        "\n",
        "        return masked_logits, masked_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEyDCtEeEynU"
      },
      "outputs": [],
      "source": [
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_logits = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, predicate_idx, padded_labels = batch\n",
        "            input_ids, predicate_idx, padded_labels = input_ids.to(device), predicate_idx.to(device), padded_labels.to(device)\n",
        "\n",
        "            \n",
        "\n",
        "            logits, labels = model(input_ids, predicate_idx, padded_labels)\n",
        "\n",
        "            loss = criterion(logits, labels.float().unsqueeze(1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            mask = labels.ne(-100)\n",
        "            valid_labels = labels[mask].cpu().numpy()\n",
        "            valid_logits = logits[mask].cpu().numpy().squeeze()\n",
        "\n",
        "            all_labels.extend(valid_labels)\n",
        "            all_logits.extend(valid_logits)\n",
        "\n",
        "    # Calculate metrics\n",
        "    #print(all_labels)\n",
        "    #print(all_logits)\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_logits = np.array(all_logits)\n",
        "    \n",
        "    all_probs = 1 / (1 + np.exp(-all_logits))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(all_labels, all_probs)\n",
        "\n",
        "    f_scores = np.where((precision + recall) != 0.0, (2 *precision * recall)/ (precision + recall + 1e-10), 0)\n",
        "  \n",
        "    best_threshold = thresholds[np.argmax(f_scores)]\n",
        "\n",
        "    # Calculate accuracy and F-score using the best threshold\n",
        "    preds = (all_probs > best_threshold).astype(int)\n",
        "    accuracy = accuracy_score(all_labels, preds)\n",
        "    best_f_score = f1_score(all_labels, preds)\n",
        "\n",
        "    return average_loss, accuracy, best_f_score, best_threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtkTC4l2E3sQ"
      },
      "outputs": [],
      "source": [
        "def validate_on_train(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_logits = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, predicate_idx, padded_labels = batch\n",
        "            input_ids, predicate_idx, padded_labels = input_ids.to(device), predicate_idx.to(device), padded_labels.to(device)\n",
        "\n",
        "            logits, labels = model(input_ids, predicate_idx, padded_labels)\n",
        "\n",
        "            loss = criterion(logits, labels.float().unsqueeze(1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            mask = labels.ne(-100)\n",
        "            valid_labels = labels[mask].cpu().numpy()\n",
        "            valid_logits = logits[mask].cpu().numpy().squeeze()\n",
        "\n",
        "            all_labels.extend(valid_labels)\n",
        "            all_logits.extend(valid_logits)\n",
        "\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_logits = np.array(all_logits)\n",
        "\n",
        "    all_probs = 1 / (1 + np.exp(-all_logits))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(all_labels, all_probs)\n",
        "\n",
        "    f_scores = np.where((precision + recall) != 0.0, (2 * precision * recall) / (precision + recall + 1e-10), 0)\n",
        "\n",
        "    best_threshold = thresholds[np.argmax(f_scores)]\n",
        "\n",
        "    preds = (all_probs > best_threshold).astype(int)\n",
        "    accuracy = accuracy_score(all_labels, preds)\n",
        "    best_f_score = f1_score(all_labels, preds)\n",
        "\n",
        "    return average_loss, accuracy, best_f_score, best_threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnFqfumJE6SZ"
      },
      "outputs": [],
      "source": [
        "def train_model_old(model, train_dataset, train_dataloader, val_dataloader, criterion, optimizer, num_epochs, clip_grad_value = 1, weighting_method='none', custom_value= 20):\n",
        "\n",
        "    if weighting_method != 'none':\n",
        "        negative_count = sum([1 for label_seq in train_dataset.labels for label in label_seq if label == 0])\n",
        "        positive_count = sum([1 for label_seq in train_dataset.labels for label in label_seq if label == 1])\n",
        "\n",
        "        if weighting_method == 'direct':\n",
        "            pos_weight = torch.tensor([negative_count / positive_count], device=device)\n",
        "        elif weighting_method == 'log':\n",
        "            pos_weight = torch.tensor([np.log(negative_count / positive_count)], device=device)\n",
        "        elif weighting_method == 'custom':\n",
        "            pos_weight = torch.tensor([custom_value], device=device)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid weighting_method value. It must be 'none', 'direct', 'log', or 'custom'.\")\n",
        "    else:\n",
        "        pos_weight = torch.tensor(1.0, device=device)\n",
        "\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    train_f_scores = []\n",
        "    val_f_scores = []\n",
        "    avg_train_loss_per_epoch = []\n",
        "    avg_val_loss_per_epoch = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        total_train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            model.train()\n",
        "            input_ids, predicate_idx, padded_labels = batch\n",
        "            input_ids, predicate_idx, padded_labels = input_ids.to(device), predicate_idx.to(device), padded_labels.to(device)\n",
        "\n",
        "            logits, labels = model(input_ids, predicate_idx, padded_labels)\n",
        "\n",
        "            criterion.pos_weight = pos_weight\n",
        "\n",
        "            loss = criterion(logits, labels.float().unsqueeze(1))\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_value)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "\n",
        "            #if i % 3 == 0:\n",
        "            #    print(f\"Batch {i}, Loss: {loss.item()}\")\n",
        "\n",
        "        avg_train_loss_per_epoch.append(total_train_loss / num_train_batches)\n",
        "\n",
        "        val_loss, val_accuracy, val_f_score, val_threshold = validate(model, val_dataloader, criterion)\n",
        "        avg_val_loss_per_epoch.append(val_loss)\n",
        "        print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Best F-score: {val_f_score}, Best Threshold: {val_threshold}\")\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            train_loss, train_accuracy, train_f_score, train_threshold = validate_on_train(model, train_dataloader, criterion)\n",
        "            train_accuracies.append(train_accuracy)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            train_f_scores.append(train_f_score)\n",
        "            val_f_scores.append(val_f_score)\n",
        "            print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Best F-score: {train_f_score}, Best Threshold: {train_threshold}\")\n",
        "\n",
        "    return avg_train_loss_per_epoch, avg_val_loss_per_epoch, train_accuracies, val_accuracies, train_f_scores, val_f_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9HfXrYog6Zp"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_dataset, train_dataloader, val_dataloader, criterion, optimizer, num_epochs, clip_grad_value=1, weighting_method='none', custom_value=20, patience=15):\n",
        "\n",
        "  if weighting_method != 'none':\n",
        "      negative_count = sum([1 for label_seq in train_dataset.labels for label in label_seq if label == 0])\n",
        "      positive_count = sum([1 for label_seq in train_dataset.labels for label in label_seq if label == 1])\n",
        "\n",
        "      if weighting_method == 'direct':\n",
        "          pos_weight = torch.tensor([negative_count / positive_count], device=device)\n",
        "      elif weighting_method == 'log':\n",
        "          pos_weight = torch.tensor([np.log(negative_count / positive_count)], device=device)\n",
        "      elif weighting_method == 'custom':\n",
        "          pos_weight = torch.tensor([custom_value], device=device)\n",
        "      else:\n",
        "          raise ValueError(\"Invalid weighting_method value. It must be 'none', 'direct', 'log', or 'custom'.\")\n",
        "  else:\n",
        "      pos_weight = torch.tensor(1.0, device=device)\n",
        "\n",
        "\n",
        "\n",
        "  train_accuracies = []\n",
        "  val_accuracies = []\n",
        "  train_f_scores = []\n",
        "  val_f_scores = []\n",
        "  avg_train_loss_per_epoch = []\n",
        "  avg_val_loss_per_epoch = []\n",
        "\n",
        "  # Early stopping initialization\n",
        "  best_val_accuracy = float('-inf')\n",
        "  patience_counter = 0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "      total_train_loss = 0\n",
        "      num_train_batches = 0\n",
        "\n",
        "      for i, batch in enumerate(train_dataloader):\n",
        "          model.train()\n",
        "          input_ids, predicate_idx, padded_labels = batch\n",
        "          input_ids, predicate_idx, padded_labels = input_ids.to(device), predicate_idx.to(device), padded_labels.to(device)\n",
        "\n",
        "          logits, labels = model(input_ids, predicate_idx, padded_labels)\n",
        "\n",
        "          criterion.pos_weight = pos_weight\n",
        "\n",
        "          loss = criterion(logits, labels.float().unsqueeze(1))\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_value)\n",
        "\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          total_train_loss += loss.item()\n",
        "          num_train_batches += 1\n",
        "\n",
        "\n",
        "      avg_train_loss_per_epoch.append(total_train_loss / num_train_batches)\n",
        "\n",
        "      val_loss, val_accuracy, val_f_score, val_threshold = validate(model, val_dataloader, criterion)\n",
        "      avg_val_loss_per_epoch.append(val_loss)\n",
        "      print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Best F-score: {val_f_score}, Best Threshold: {val_threshold}\")\n",
        "\n",
        "      if (epoch + 1) % 10 == 0:\n",
        "          train_loss, train_accuracy, train_f_score, train_threshold = validate_on_train(model, train_dataloader, criterion)\n",
        "          train_accuracies.append(train_accuracy)\n",
        "          val_accuracies.append(val_accuracy)\n",
        "          train_f_scores.append(train_f_score)\n",
        "          val_f_scores.append(val_f_score)\n",
        "          print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Best F-score: {train_f_score}, Best Threshold: {train_threshold}\")\n",
        "\n",
        "      # Early stopping\n",
        "      if val_accuracy > best_val_accuracy:\n",
        "          best_val_accuracy = val_accuracy\n",
        "          patience_counter = 0\n",
        "      else:\n",
        "          patience_counter += 1\n",
        "\n",
        "      if patience_counter >= patience:\n",
        "          print(f\"Early stopping triggered after {epoch + 1} epochs due to no improvement in validation accuracy\")\n",
        "          num_missing_values = num_epochs - epoch - 1\n",
        "          train_accuracies.extend([None] * num_missing_values)\n",
        "          val_accuracies.extend([None] * num_missing_values)\n",
        "          train_f_scores.extend([None] * num_missing_values)\n",
        "          val_f_scores.extend([None] * num_missing_values)\n",
        "\n",
        "          #return avg_train_loss_per_epoch, avg_val_loss_per_epoch, train_accuracies, val_accuracies, train_f_scores, val_f_scores\n",
        "          return avg_train_loss_per_epoch, avg_val_loss_per_epoch, train_accuracies, val_accuracies, train_f_scores, val_f_scores\n",
        "          \n",
        "\n",
        "  return avg_train_loss_per_epoch, avg_val_loss_per_epoch, train_accuracies, val_accuracies, train_f_scores, val_f_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaWg8iT3jd-m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ_M5pjqFPPa"
      },
      "outputs": [],
      "source": [
        "hyper_parameter_dict = {'learning_rate': [1e-4,1e-5,2e-4,2e-5], 'clip_grad_value':[1.0,1.2,1.6,2.0], 'lstm_hidden_size':[50,128,80,96,200], 'dropout_rate':[0.2,0.3,0.1], \n",
        "                        'custom_weight_value': [27, 20, 15 ,27, 40] }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5mOFKbAMmq4",
        "outputId": "c47e6a21-80ad-4dff-f0ef-b7a0d6094ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cazV04IMvpn"
      },
      "outputs": [],
      "source": [
        "num_labels = 1\n",
        "hidden_size = 768"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoEHr59_HHvn"
      },
      "outputs": [],
      "source": [
        "max_length = 128\n",
        "train_dataset = SRLDataset(train_sentences, train_predicates, train_labels, tokenizer, max_length)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsBi0Wk-L92w"
      },
      "outputs": [],
      "source": [
        "max_length = 128\n",
        "val_dataset = SRLDataset(val_sentences, val_predicates, val_labels, tokenizer, max_length)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-7X-QIYjrGg",
        "outputId": "126cd612-6844-4a90-fd45-e5d02e5140cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241285\n",
            "8754\n",
            "tensor([27.5628])\n"
          ]
        }
      ],
      "source": [
        "negative_count = sum([1 for label_seq in train_dataset.labels for label in label_seq if label == 0])\n",
        "print(negative_count)\n",
        "positive_count = sum([1 for label_seq in train_dataset.labels for label in label_seq if label == 1])\n",
        "print(positive_count)\n",
        "pos_weight = torch.tensor([negative_count / positive_count ], device=device)\n",
        "print(pos_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TggFQaBbMNZD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def grid_search_old(hyper_parameter_dict, train_dataset, train_dataloader, val_dataloader, criterion, num_epochs):\n",
        "    # Create all possible combinations of hyperparameters\n",
        "    hyper_parameter_combinations = list(itertools.product(*hyper_parameter_dict.values()))\n",
        "\n",
        "    # Initialize a pandas DataFrame to store the results\n",
        "    columns = list(hyper_parameter_dict.keys()) + ['val_accuracies', 'val_f_scores', 'train_accuracies', 'train_f_scores']\n",
        "    results_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    # Iterate over all hyperparameter combinations\n",
        "    for config in hyper_parameter_combinations:\n",
        "        print(f\"Training with hyperparameter configuration: {config}\")\n",
        "        learning_rate, clip_grad_value, lstm_hidden_size, dropout_rate, custom_weight_value = config\n",
        "\n",
        "        # Initialize the model with the current configuration\n",
        "        model = SRLModel(bert_model, hidden_size, num_labels, lstm_hidden_size=lstm_hidden_size, dropout_rate=dropout_rate, patience = 15).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Train the model with the current configuration\n",
        "        _, _, train_accuracies, val_accuracies, train_f_scores, val_f_scores = train_model(\n",
        "            model, train_dataset, train_dataloader, val_dataloader, criterion, optimizer, num_epochs,\n",
        "            clip_grad_value=clip_grad_value, weighting_method='custom', custom_value=custom_weight_value\n",
        "        )\n",
        "\n",
        "        # Store the results in the DataFrame\n",
        "        results_df = results_df.append(\n",
        "            {**dict(zip(hyper_parameter_dict.keys(), config)),\n",
        "             'val_accuracies': val_accuracies,\n",
        "             'val_f_scores': val_f_scores,\n",
        "             'train_accuracies': train_accuracies,\n",
        "             'train_f_scores': train_f_scores},\n",
        "            ignore_index=True\n",
        "        )\n",
        "\n",
        "    # Save the results to a file\n",
        "    results_df.to_csv(\"grid_search_results.csv\", index=False)\n",
        "\n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziRiEvEvnsoT"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import ast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rllJ2fmAn3SH"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiKTA11rnU5a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def grid_search(hyper_parameter_dict, results_csv_path):\n",
        "    # Create the CSV file and write the header\n",
        "    with open(results_csv_path, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['learning_rate', 'clip_grad_value', 'lstm_hidden_size', 'dropout_rate', 'custom_weight_value', 'train_accuracies', 'train_f_scores', 'val_accuracies', 'val_f_scores']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "    for config in itertools.product(*hyper_parameter_dict.values()):\n",
        "        print(f\"Training with hyperparameter configuration: {config}\")\n",
        "        learning_rate, clip_grad_value, lstm_hidden_size, dropout_rate, custom_weight_value = config\n",
        "\n",
        "        # Train the model with the current configuration of hyperparameters\n",
        "        model = SRLModel(bert_model, hidden_size, num_labels, lstm_hidden_size=lstm_hidden_size, dropout_rate=dropout_rate).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        avg_train_loss_per_epoch, avg_val_loss_per_epoch, train_accuracies, val_accuracies, train_f_scores, val_f_scores = train_model(model, train_dataset, train_dataloader, val_dataloader, criterion, optimizer, num_epochs, clip_grad_value, weighting_method='custom', custom_value=custom_weight_value, patience = 15)\n",
        "\n",
        "        # Save the current configuration and its results to the CSV file\n",
        "        results_dict = {'learning_rate': learning_rate, 'clip_grad_value': clip_grad_value, 'lstm_hidden_size': lstm_hidden_size, 'dropout_rate': dropout_rate, 'custom_weight_value': custom_weight_value, 'train_accuracies': str(train_accuracies), 'train_f_scores': str(train_f_scores), 'val_accuracies': str(val_accuracies), 'val_f_scores': str(val_f_scores)}\n",
        "        \n",
        "        with open(results_csv_path, 'a', newline='') as csvfile:\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writerow(results_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZvCzL4-nqr-"
      },
      "outputs": [],
      "source": [
        "\n",
        "results_csv_path = 'grid_search_results_sequential_new.csv'\n",
        "#grid_search(hyper_parameter_dict, results_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBPV05RxNBYD"
      },
      "outputs": [],
      "source": [
        "grid_search(hyper_parameter_dict, results_csv_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNS8WWFtsMzJmvSaBRnVGp6",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}